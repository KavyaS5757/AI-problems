{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8155698,"sourceType":"datasetVersion","datasetId":4824303}],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-20T13:21:22.195975Z","iopub.execute_input":"2024-04-20T13:21:22.196375Z","iopub.status.idle":"2024-04-20T13:21:23.054554Z","shell.execute_reply.started":"2024-04-20T13:21:22.196343Z","shell.execute_reply":"2024-04-20T13:21:23.053641Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/breast-cancer-dataset/Y_train.npy\n/kaggle/input/breast-cancer-dataset/X_test.npy\n/kaggle/input/breast-cancer-dataset/X_train.npy\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\n\n# Load the data\nX_train = np.load('/kaggle/input/breast-cancer-dataset/X_train.npy')\nY_train = np.load('/kaggle/input/breast-cancer-dataset/Y_train.npy')\nX_test = np.load('/kaggle/input/breast-cancer-dataset/X_test.npy')\n\n# Normalize pixel values\nX_train = X_train / 255.0\nX_test = X_test / 255.0\n\n# Reshape Y_train\nY_train = Y_train.flatten()\n\n# Split the test dataset into test and validation sets\ntest_split_ratio = 0.5\nsplit_index = int(len(X_test) * test_split_ratio)\n\nX_test_split = X_test[:split_index]\nX_val_split = X_test[split_index:]\n\n# Save the split test and validation datasets as .npy files\nnp.save('X_test_split.npy', X_test_split)\nnp.save('X_val_split.npy', X_val_split)\n\n# Print the shapes of the split datasets\nprint(\"X_test_split shape:\", X_test_split.shape)\nprint(\"X_val_split shape:\", X_val_split.shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-20T13:21:23.056760Z","iopub.execute_input":"2024-04-20T13:21:23.057271Z","iopub.status.idle":"2024-04-20T13:21:37.278330Z","shell.execute_reply.started":"2024-04-20T13:21:23.057237Z","shell.execute_reply":"2024-04-20T13:21:37.277338Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-04-20 13:21:24.580624: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-20 13:21:24.580720: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-20 13:21:24.689341: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"X_test_split shape: (693, 50, 50, 3)\nX_val_split shape: (694, 50, 50, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Confirm the shapes\nprint(\"Shapes of X_train and Y_train:\", X_train.shape, Y_train.shape)\nprint(\"Shapes of X_test and Y_test:\", X_test.shape, Y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-20T13:21:37.279446Z","iopub.execute_input":"2024-04-20T13:21:37.280018Z","iopub.status.idle":"2024-04-20T13:21:37.640992Z","shell.execute_reply.started":"2024-04-20T13:21:37.279990Z","shell.execute_reply":"2024-04-20T13:21:37.639261Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Shapes of X_train and Y_train: (4160, 50, 50, 3) (4160,)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Confirm the shapes\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShapes of X_train and Y_train:\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_train\u001b[38;5;241m.\u001b[39mshape, Y_train\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShapes of X_test and Y_test:\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_test\u001b[38;5;241m.\u001b[39mshape, \u001b[43mY_test\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n","\u001b[0;31mNameError\u001b[0m: name 'Y_test' is not defined"],"ename":"NameError","evalue":"name 'Y_test' is not defined","output_type":"error"}]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\n\nclass NumpyDataGenerator(tf.keras.utils.Sequence):\n    def __init__(self, X, y, batch_size=32, shuffle=True):\n        self.X = X\n        self.y = y\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.indexes = np.arange(len(self.X))\n        if self.shuffle:\n            np.random.shuffle(self.indexes)\n    \n    def __len__(self):\n        return len(self.X) // self.batch_size\n    \n    def __getitem__(self, index):\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        batch_X = self.X[indexes]\n        batch_y = self.y[indexes]\n        return batch_X, batch_y\n    \n    def on_epoch_end(self):\n        if self.shuffle:\n            np.random.shuffle(self.indexes)\n\n\n# Load the data\nX_train = np.load('/kaggle/input/breast-cancer-dataset/X_train.npy')\nY_train = np.load('/kaggle/input/breast-cancer-dataset/Y_train.npy')\n\n# Load the split test and validation datasets\nX_test = np.load('/kaggle/working/X_test_split.npy')\nY_test = np.load('/kaggle/working/X_val_split.npy')            \n# Load the data\n#X_train = np.load('/kaggle/input/breast-cancer-dataset/X_train.npy')\n#Y_train = np.load('/kaggle/input/breast-cancer-dataset/Y_train.npy')\n#X_test = np.load('/kaggle/input/breast-cancer-dataset/X_test.npy')\n#Y_test = np.load('/kaggle/input/breast-cancer-dataset/X_test.npy')\n\n# Normalize pixel values\nX_train = X_train / 255.0\nX_test = X_test / 255.0\n\n# Reshape Y_train and Y_test\nY_train = Y_train.flatten()\nY_test = Y_test.flatten()\n\n# Define batch size\nbatch_size = 32\n\n# Create data generators\ntrain_generator = NumpyDataGenerator(X_train, Y_train, batch_size=batch_size)\ntest_generator = NumpyDataGenerator(X_test, Y_test, batch_size=batch_size)\n\n# Define the model\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(50, 50, 3)),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\n# Compile the model\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\n# Train the model\nmodel.fit(train_generator, epochs=10, validation_data=test_generator)\n\n# Evaluate the model\ntest_loss, test_acc = model.evaluate(test_generator)\nprint(\"Test Accuracy:\", test_acc)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-20T13:22:04.716849Z","iopub.execute_input":"2024-04-20T13:22:04.717235Z","iopub.status.idle":"2024-04-20T13:22:16.259251Z","shell.execute_reply.started":"2024-04-20T13:22:04.717199Z","shell.execute_reply":"2024-04-20T13:22:16.258286Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n2024-04-20 13:22:08.391971: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 511: 3.99746, expected 3.4575\n2024-04-20 13:22:08.392064: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4608: 6.74587, expected 5.87283\n2024-04-20 13:22:08.392075: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4609: 6.53509, expected 5.66205\n2024-04-20 13:22:08.392083: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4610: 6.96058, expected 6.08753\n2024-04-20 13:22:08.392092: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4611: 6.70752, expected 5.83448\n2024-04-20 13:22:08.392100: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4612: 6.81476, expected 5.94172\n2024-04-20 13:22:08.392108: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4613: 6.40484, expected 5.5318\n2024-04-20 13:22:08.392117: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4614: 6.13134, expected 5.2583\n2024-04-20 13:22:08.392125: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4615: 6.55867, expected 5.68564\n2024-04-20 13:22:08.392133: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4616: 6.51293, expected 5.63989\n2024-04-20 13:22:08.392151: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[32,32,48,48]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,3,50,50]{3,2,1,0}, f32[32,3,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=2,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-04-20 13:22:08.392161: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-04-20 13:22:08.392168: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-04-20 13:22:08.392175: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n2024-04-20 13:22:08.392182: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-04-20 13:22:08.392194: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-04-20 13:22:08.549744: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 511: 3.99746, expected 3.4575\n2024-04-20 13:22:08.549814: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4608: 6.74587, expected 5.87283\n2024-04-20 13:22:08.549824: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4609: 6.53509, expected 5.66205\n2024-04-20 13:22:08.549832: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4610: 6.96058, expected 6.08753\n2024-04-20 13:22:08.549840: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4611: 6.70752, expected 5.83448\n2024-04-20 13:22:08.549848: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4612: 6.81476, expected 5.94172\n2024-04-20 13:22:08.549856: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4613: 6.40484, expected 5.5318\n2024-04-20 13:22:08.549864: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4614: 6.13134, expected 5.2583\n2024-04-20 13:22:08.549872: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4615: 6.55867, expected 5.68564\n2024-04-20 13:22:08.549879: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4616: 6.51293, expected 5.63989\n2024-04-20 13:22:08.550404: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[32,32,48,48]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,3,50,50]{3,2,1,0}, f32[32,3,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=2,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-04-20 13:22:08.550431: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-04-20 13:22:08.550439: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-04-20 13:22:08.550445: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n2024-04-20 13:22:08.550452: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-04-20 13:22:08.550464: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 49/130\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5080 - loss: 0.7255","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1713619330.243799      82 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5098 - loss: 0.7088 - val_accuracy: 0.0000e+00 - val_loss: 0.6870\nEpoch 2/10\n\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5097 - loss: 0.6931 - val_accuracy: 0.0000e+00 - val_loss: 0.6868\nEpoch 3/10\n\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4942 - loss: 0.6933 - val_accuracy: 0.0000e+00 - val_loss: 0.6872\nEpoch 4/10\n\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5094 - loss: 0.6931 - val_accuracy: 0.0000e+00 - val_loss: 0.6881\nEpoch 5/10\n\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5040 - loss: 0.6931 - val_accuracy: 0.0000e+00 - val_loss: 0.6895\nEpoch 6/10\n\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5000 - loss: 0.6932 - val_accuracy: 0.0000e+00 - val_loss: 0.6889\nEpoch 7/10\n\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4986 - loss: 0.6932 - val_accuracy: 0.0000e+00 - val_loss: 0.6878\nEpoch 8/10\n\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4912 - loss: 0.6933 - val_accuracy: 0.0000e+00 - val_loss: 0.6884\nEpoch 9/10\n\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4972 - loss: 0.6932 - val_accuracy: 0.0000e+00 - val_loss: 0.6887\nEpoch 10/10\n\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5050 - loss: 0.6931 - val_accuracy: 0.0000e+00 - val_loss: 0.6892\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.6892 \nTest Accuracy: 0.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\n# Convert probabilities to binary labels\npredicted_labels = (predictions > 0.5).astype(int).flatten()\n\n# Evaluate the model\nfrom sklearn.metrics import classification_report\n\ntrue_labels = Y_test[:len(predictions)].astype(int)  # Ensure true labels have the same length as predictions\nprint(classification_report(true_labels, predicted_labels))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-20T13:24:12.705125Z","iopub.execute_input":"2024-04-20T13:24:12.705497Z","iopub.status.idle":"2024-04-20T13:24:12.722853Z","shell.execute_reply.started":"2024-04-20T13:24:12.705468Z","shell.execute_reply":"2024-04-20T13:24:12.721786Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00     672.0\n           1       0.00      0.00      0.00       0.0\n\n    accuracy                           0.00     672.0\n   macro avg       0.00      0.00      0.00     672.0\nweighted avg       0.00      0.00      0.00     672.0\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\n\nclass NumpyDataGenerator(tf.keras.utils.Sequence):\n    def __init__(self, X, y, batch_size=32, shuffle=True, augment=False):\n        self.X = X\n        self.y = y\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.augment = augment  # Flag for data augmentation\n        self.indexes = np.arange(len(self.X))\n        if self.shuffle:\n            np.random.shuffle(self.indexes)\n    \n    def __len__(self):\n        return len(self.X) // self.batch_size\n    \n    def __getitem__(self, index):\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        batch_X = self.X[indexes]\n        batch_y = self.y[indexes]\n        if self.augment:\n            batch_X = self.apply_augmentation(batch_X)\n        return batch_X, batch_y\n    \n    def on_epoch_end(self):\n        if self.shuffle:\n            np.random.shuffle(self.indexes)\n            \n    def apply_augmentation(self, batch_X):\n        # Apply data augmentation techniques\n        # Example: random horizontal flip\n        batch_X = tf.image.random_flip_left_right(batch_X)\n        return batch_X\n    \n#     def apply_augmentation(self, batch_X):\n#         # Apply data augmentation techniques\n#         batch_X = tf.image.random_flip_left_right(batch_X)\n#     # Randomly rotate the image by 90-degree increments\n#         batch_X = tf.image.rot90(batch_X, tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n#     # Randomly zoom into the image by a factor between 0.8 and 1.2\n#         height, width = tf.shape(batch_X)[1], tf.shape(batch_X)[2]\n#         new_height = tf.random.uniform(shape=[], minval=int(0.8 * tf.cast(height, tf.float32)), maxval=int(1.2 * tf.cast(height, tf.float32)), dtype=tf.int32)\n#         new_width = tf.random.uniform(shape=[], minval=int(0.8 * tf.cast(width, tf.float32)), maxval=int(1.2 * tf.cast(width, tf.float32)), dtype=tf.int32)\n#         batch_X = tf.image.resize(batch_X, (new_height, new_width))\n#         return batch_X\n\n\n\n# Load the data\nX_train = np.load('/kaggle/input/breast-cancer-dataset/X_train.npy')\nY_train = np.load('/kaggle/input/breast-cancer-dataset/Y_train.npy')\n\n# Load the split test and validation datasets\nX_test = np.load('/kaggle/working/X_test_split.npy')\nY_test = np.load('/kaggle/working/X_val_split.npy')            \n\n# Normalize pixel values\nX_train = X_train / 255.0\nX_test = X_test / 255.0\n\n# Reshape Y_train and Y_test\nY_train = Y_train.flatten()\nY_test = Y_test.flatten()\n\n# Define batch size\nbatch_size = 32\n\n# Create data generators with augmentation enabled for training data\ntrain_generator = NumpyDataGenerator(X_train, Y_train, batch_size=batch_size, augment=True)\ntest_generator = NumpyDataGenerator(X_test, Y_test, batch_size=batch_size)\n\n# Define the model with dropout regularization\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(50, 50, 3)),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dropout(0.5),  # Add dropout layer with dropout rate of 0.5\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\n# Compile the model\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\n# Train the model\nmodel.fit(train_generator, epochs=10, validation_data=test_generator)\n\n# Evaluate the model\ntest_loss, test_acc = model.evaluate(test_generator)\nprint(\"Test Accuracy:\", test_acc)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-20T13:28:33.803628Z","iopub.execute_input":"2024-04-20T13:28:33.804568Z","iopub.status.idle":"2024-04-20T13:28:44.596046Z","shell.execute_reply.started":"2024-04-20T13:28:33.804536Z","shell.execute_reply":"2024-04-20T13:28:44.595179Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5804 - loss: 0.6783 - val_accuracy: 0.0000e+00 - val_loss: 0.6168\nEpoch 2/10\n\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6877 - loss: 0.6077 - val_accuracy: 0.0000e+00 - val_loss: 0.6522\nEpoch 3/10\n\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7132 - loss: 0.5765 - val_accuracy: 0.0000e+00 - val_loss: 0.8259\nEpoch 4/10\n\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7310 - loss: 0.5537 - val_accuracy: 0.0000e+00 - val_loss: 0.9405\nEpoch 5/10\n\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7039 - loss: 0.5810 - val_accuracy: 0.0000e+00 - val_loss: 0.8354\nEpoch 6/10\n\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7279 - loss: 0.5694 - val_accuracy: 0.0000e+00 - val_loss: 0.7672\nEpoch 7/10\n\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7502 - loss: 0.5300 - val_accuracy: 0.0000e+00 - val_loss: 4.4206\nEpoch 8/10\n\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7410 - loss: 0.5383 - val_accuracy: 0.0000e+00 - val_loss: 6.5048\nEpoch 9/10\n\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7450 - loss: 0.5388 - val_accuracy: 0.0000e+00 - val_loss: 1.8988\nEpoch 10/10\n\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7509 - loss: 0.5322 - val_accuracy: 0.0000e+00 - val_loss: 2.1380\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 2.1325 \nTest Accuracy: 0.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\n\nclass NumpyDataGenerator(tf.keras.utils.Sequence):\n    def __init__(self, X, y, batch_size=32, shuffle=True):\n        self.X = X\n        self.y = y\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.indexes = np.arange(len(self.X))\n        if self.shuffle:\n            np.random.shuffle(self.indexes)\n    \n    def __len__(self):\n        return len(self.X) // self.batch_size\n    \n    def __getitem__(self, index):\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        batch_X = self.X[indexes]\n        batch_y = self.y[indexes]\n        return batch_X, batch_y\n    \n    def on_epoch_end(self):\n        if self.shuffle:\n            np.random.shuffle(self.indexes)\n\n\n# Load the data\nX_train = np.load('/kaggle/input/breast-cancer-dataset/X_train.npy')\nY_train = np.load('/kaggle/input/breast-cancer-dataset/Y_train.npy')\n\n# Normalize pixel values\nX_train = X_train / 255.0\n\n# Reshape Y_train\nY_train = Y_train.flatten()\n\n# Define batch size\nbatch_size = 32\n\n# Create data generator\ntrain_generator = NumpyDataGenerator(X_train, Y_train, batch_size=batch_size)\n\n# Define the model\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(50, 50, 3)),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\n# Compile the model\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\n# Train the model\nmodel.fit(train_generator, epochs=10)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-20T13:28:48.042724Z","iopub.execute_input":"2024-04-20T13:28:48.043593Z","iopub.status.idle":"2024-04-20T13:28:54.585409Z","shell.execute_reply.started":"2024-04-20T13:28:48.043560Z","shell.execute_reply":"2024-04-20T13:28:54.584356Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5337 - loss: 0.6930\nEpoch 2/10\n\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6831 - loss: 0.6021\nEpoch 3/10\n\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7257 - loss: 0.5649\nEpoch 4/10\n\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7328 - loss: 0.5573\nEpoch 5/10\n\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7314 - loss: 0.5385\nEpoch 6/10\n\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7622 - loss: 0.5151\nEpoch 7/10\n\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7370 - loss: 0.5407\nEpoch 8/10\n\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7389 - loss: 0.5362\nEpoch 9/10\n\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7462 - loss: 0.5201\nEpoch 10/10\n\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7569 - loss: 0.5242\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7dd937cf4dc0>"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\n# Load the single test data file\nX_test_single = np.load('/kaggle/input/breast-cancer-dataset/X_test.npy')\n\n# Normalize pixel values\nX_test_single = X_test_single / 255.0\n\n# Reshape the data if necessary\n# X_test_single = np.reshape(X_test_single, (num_samples, width, height, num_channels))\n\n# Make predictions using the trained model\npredictions = model.predict(X_test_single)\n\n# If your model predicts probabilities, you may want to convert them to class labels\n# For example, if your model is trained for binary classification with sigmoid activation\nclass_labels = (predictions > 0.5).astype(int)\n\n# Print the predictions\nprint(class_labels)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-20T13:29:04.902755Z","iopub.execute_input":"2024-04-20T13:29:04.903108Z","iopub.status.idle":"2024-04-20T13:29:06.034926Z","shell.execute_reply.started":"2024-04-20T13:29:04.903083Z","shell.execute_reply":"2024-04-20T13:29:06.033948Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"\u001b[1m33/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step   ","output_type":"stream"},{"name":"stderr","text":"2024-04-20 13:29:05.575517: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4611: 8.58576, expected 7.6197\n2024-04-20 13:29:05.575571: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4613: 8.21984, expected 7.25378\n2024-04-20 13:29:05.575580: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4615: 7.96022, expected 6.99417\n2024-04-20 13:29:05.575589: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4617: 8.55713, expected 7.59108\n2024-04-20 13:29:05.575597: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4618: 8.62198, expected 7.65593\n2024-04-20 13:29:05.575605: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4619: 7.93489, expected 6.96883\n2024-04-20 13:29:05.575613: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4620: 8.58683, expected 7.62077\n2024-04-20 13:29:05.575630: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4621: 8.53004, expected 7.56399\n2024-04-20 13:29:05.575638: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4625: 8.18762, expected 7.22157\n2024-04-20 13:29:05.575646: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4626: 7.99505, expected 7.02899\n2024-04-20 13:29:05.575660: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[11,32,48,48]{3,2,1,0}, u8[0]{0}) custom-call(f32[11,3,50,50]{3,2,1,0}, f32[32,3,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=2,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-04-20 13:29:05.575668: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-04-20 13:29:05.575675: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-04-20 13:29:05.575682: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n2024-04-20 13:29:05.575689: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-04-20 13:29:05.575698: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-04-20 13:29:05.601703: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4611: 8.58576, expected 7.6197\n2024-04-20 13:29:05.601735: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4613: 8.21984, expected 7.25378\n2024-04-20 13:29:05.601744: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4615: 7.96022, expected 6.99417\n2024-04-20 13:29:05.601752: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4617: 8.55713, expected 7.59108\n2024-04-20 13:29:05.601760: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4618: 8.62198, expected 7.65593\n2024-04-20 13:29:05.601768: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4619: 7.93489, expected 6.96883\n2024-04-20 13:29:05.601776: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4620: 8.58683, expected 7.62077\n2024-04-20 13:29:05.601784: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4621: 8.53004, expected 7.56399\n2024-04-20 13:29:05.601792: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4625: 8.18762, expected 7.22157\n2024-04-20 13:29:05.601800: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4626: 7.99505, expected 7.02899\n2024-04-20 13:29:05.601813: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[11,32,48,48]{3,2,1,0}, u8[0]{0}) custom-call(f32[11,3,50,50]{3,2,1,0}, f32[32,3,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=2,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-04-20 13:29:05.601824: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-04-20 13:29:05.601835: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-04-20 13:29:05.601844: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n2024-04-20 13:29:05.601854: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-04-20 13:29:05.601869: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n[[0]\n [1]\n [1]\n ...\n [1]\n [1]\n [1]]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Convert probabilities to binary class labels\nclass_labels = (predictions > 0.5).astype(int).flatten()\n\n# Count the occurrences of each class label\nnum_benign = np.sum(class_labels == 0)\nnum_malignant = np.sum(class_labels == 1)\n\nprint(\"Number of benign instances:\", num_benign)\nprint(\"Number of malignant instances:\", num_malignant)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-20T13:32:10.849614Z","iopub.execute_input":"2024-04-20T13:32:10.850259Z","iopub.status.idle":"2024-04-20T13:32:10.856406Z","shell.execute_reply.started":"2024-04-20T13:32:10.850231Z","shell.execute_reply":"2024-04-20T13:32:10.855422Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Number of benign instances: 655\nNumber of malignant instances: 732\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\n# Convert probabilities to binary class labels\nclass_labels = (predictions > 0.5).astype(int).flatten()\n\n# Create a DataFrame with the test dataset and predicted labels\ntest_df = pd.DataFrame({'ImageId': np.arange(len(class_labels)) + 1, 'Label': class_labels})\n\n# Separate into benign and malignant DataFrames\nbenign_df = test_df[test_df['Label'] == 0]\nmalignant_df = test_df[test_df['Label'] == 1]\n\n# Save to CSV files\nbenign_df.to_csv('/kaggle/working/benign_predictions.csv', index=False)\nmalignant_df.to_csv('/kaggle/working/malignant_predictions.csv', index=False)\n\nprint(\"CSV files saved successfully.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-20T14:04:26.415771Z","iopub.execute_input":"2024-04-20T14:04:26.416483Z","iopub.status.idle":"2024-04-20T14:04:26.437318Z","shell.execute_reply.started":"2024-04-20T14:04:26.416455Z","shell.execute_reply":"2024-04-20T14:04:26.436382Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"CSV files saved successfully.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}